{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f01cf1b",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "***\n",
    "**Models**\n",
    "* Basel Face Model (BFM'09): click here to obtain it from the University of Basel\n",
    "* Expression Model Click ***\n",
    "\n",
    "**Software**\n",
    "* CUDA (tested with v11.0)\n",
    "* OpenCV (tested with v4.5)\n",
    "* Python 3\n",
    "\n",
    "The following python packages are also needed, but these can be installed by following the instructions in Section 2 of Installation below.\n",
    "* cvxpy (for temporal smoothing via post-processing)\n",
    "* scikit-learn\n",
    "* matplotlib\n",
    "* opencv-python\n",
    "\n",
    "# Installation\n",
    "***\n",
    "\n",
    "\n",
    "### 1) Compile CUDA code\n",
    "Clone the git repository and compile the CUDA code as below\n",
    "\n",
    "```\n",
    "cd build \n",
    "chmod +x builder.sh\n",
    "./builder.sh\n",
    "```\n",
    "\n",
    "### 2) Install python packages\n",
    "\n",
    "Install the necessary packages via pip. It is advised to use a virtual environment by running\n",
    "```\n",
    "cd build\n",
    "python -m venv env\n",
    "source env/bin/activate\n",
    "\n",
    "```\n",
    "\n",
    "The necessary packages can simply be installed by running.\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 3) Pre-process Morphable Models\n",
    "\n",
    "Make sure that you downloaded the Basel Face Model (`01_MorphableModel.mat`) and the Expression Model (`Exp_Pca.bin`) as highlighted in the Requirements section above. Then, copy these model files into the `build/models/raw` directory. Specifically, these files should be in the following locations:\n",
    "```\n",
    "build/models/raw/01_MorphableModel.mat\n",
    "build/models/raw/Exp_Pca.bin\n",
    "```\n",
    "\n",
    "Then run the following python script to adapt these models to the 3DI code:\n",
    "```\n",
    "cd build/models\n",
    "python prepare_BFM.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65fe19",
   "metadata": {},
   "source": [
    "# Running the code\n",
    "***\n",
    "\n",
    "### Quickstart\n",
    "Go to the `build` directory and, if you used a virtual environment, activate it by running `source env/bin/activate`.\n",
    "\n",
    "Then, you can process a video by running the following command\n",
    "\n",
    "```\n",
    "python process_video.py #output_directory# #videopath# \n",
    "```\n",
    "\n",
    "The following is an example command (will produce visuals as well)\n",
    "```\n",
    "python process_video.py ./output testdata/elaine.mp4 --***\n",
    "```\n",
    "The produced files are in the *** directory. The script above takes *** seconds to run, and this includes the production of the visualization parameters as well as temporal smoothing. Visualization or smoothing can be disabled by following here***. Moreover, the process can be sped up by running 3DI with a faster configuration file *** . Detailed speed evaluation and comparison of the default and a faster configuration file are provided here***. \n",
    "\n",
    "The `process_video.py` script does a series of pre- and post-processing for reconstruction (details are [here](#details-of-video-processing)). It is important to know that we **first estimate the identity parameters** of the subject in the video, by using a small subset of the video frames, and then we compute pose and expression coefficients at every frame. Thus, the identity parameters are held common throughout the video.\n",
    "\n",
    "\n",
    "### Options of `process_video.py`\n",
    "   \n",
    "Running with custom camera model\n",
    "\n",
    "\n",
    "\n",
    "### Details of video processing\n",
    "\n",
    "\n",
    "The `process_video.py` script does a series of processes on the video. Specifically, it does the following steps in this order:\n",
    "1. Face detection on the entire video\n",
    "1. Facial landmark detection on the entire video\n",
    "1. 3D (neutral) identity parameter estimation via 3DI (using a subset of frames from the videos)\n",
    "1. Frame-by-frame 3D reconstruction via 3DI (identity parameters are fixed here to the ones produced in the previous step)\n",
    "1. (Optional) Temporal smoothing\n",
    "1. (Optional) Production of 3D reconstruction videos (similar to these###)\n",
    "1. (Optional) Production of video with 2D landmarks estimated by 3DI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137b11a",
   "metadata": {},
   "source": [
    "The first four steps are visualized below; the blue text indicates the extension of the corresponding files\n",
    "\n",
    "<img src=\"process_video1.png\"  alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "The smoothing steps are optional but strongly suggested\n",
    "\n",
    "<img src=\"process_video2.png\"  alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "The 2D landmarks estimated by 3DI are also produced optionally based on the files produced above.\n",
    "\n",
    "<img src=\"process_video3.png\"  alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
